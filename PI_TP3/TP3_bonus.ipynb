{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptions&Interactions TP3 - Traitement d'image, Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Imports et chargement d'image*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"lena_gray.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercices bonus\n",
    "\n",
    "### 4. Features from Accelerated Segment Test (FAST)\n",
    "\n",
    "FAST est un algorithme de détection de points d'intérêt. Pour chaque pixel, un cercle de rayon 3 des pixels \"voisins\" est calculé. Tout d'abord, on peut définir un tel cercle tel que :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bresenham_circle():\n",
    "    circle = np.zeros((7,7))\n",
    "    for i in range(circle.shape[0]):\n",
    "        for j in range(circle.shape[1]):\n",
    "            distance = np.sqrt((3-i)*(3-i) + (3-j)*(3-j))\n",
    "            if distance > 2.5 and distance < 3.5:\n",
    "                circle[i, j] = 1\n",
    "    return circle\n",
    "plt.imshow(bresenham_circle())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce cercle pourra ensuite être utilisé de manière similaire aux noyaux de la fonction convolution. Le cercle est composé de 16 pixels. Pour chaque pixel du cercle, on vérifie si sa différence d'intensité avec le pixel du centre du cercle est supérieure au threshold donné en paramètre. Si au moins 12 des 16 pixels du cercle ont une différence supérieure à ce threshold, alors le pixel est considéré comme un point d'intérêt.\n",
    "\n",
    "La fonction fast retourne un tableau contenant n paires de coordonnées (i,j), n étant le nombre de points d'intérêts trouvés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast(img, threshold):\n",
    "    circle = bresenham_circle()\n",
    "    # ...\n",
    "    return\n",
    "\n",
    "def show_keypoints(img, keypoints):\n",
    "    img_show_keypoints = np.stack((img.copy(), img.copy(), img.copy()), axis=2)\n",
    "    for kp in keypoints:\n",
    "        (i,j) = kp\n",
    "        img_show_keypoints[i-1:i+1, j-1:j+1, 1] = 255\n",
    "    plt.imshow(img_show_keypoints)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew_d = cv2.imread(\"Crew_Dragon.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "capsule = cv2.imread(\"capsule.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Attention, prend beaucoup de temps\n",
    "#kp_cd = fast(crew_d, 50)\n",
    "\n",
    "show_keypoints(crew_d, kp_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention, prend beaucoup de temps\n",
    "kp_caps = fast(capsule, 50)\n",
    "\n",
    "show_keypoints(capsule, kp_caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Binary Robust Independent Elementary Features (BRIEF)\n",
    "\n",
    "BRIEF calcule des descripteurs pour chaque point d'intérêt. Tout d'abord, un flou est effectué sur l'image d'entrée pour diminuer le niveau de bruit. Il est possible d'utiliser un flou tel que codé précédemment avec les fonctions moyenne_voisins ou convolution, ou alors d'utiliser un flou gaussien à l'aide des deux lignes suivantes (si supporté par l'installation Python du CREMI...) :\n",
    "> from scipy.ndimage import gaussian_filter\n",
    "> \n",
    "> gaussian_filter(img, sigma=2)\n",
    "\n",
    "On cherche alors à obtenir un descripteur, ici un vecteur de taille 128, pour chaque pixel détecté comme un point d'intérêt par FAST. On considère le voisinage de ce pixel (carré de taille 9x9). Dans ce voisinage, 128 paires de pixels (A,B) sont sélectionnées aléatoirement. Pour chacune de ces paires, si img(A) < img(B), alors le vecteur prend la valeur 1 (dans la case correspondant au numéro de la paire considérée). Dans le cas contraire, le vecteur prend la valeur 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def brief(img, keypoints):\n",
    "    # ...\n",
    "    return\n",
    "\n",
    "desc_cd = brief(crew_d, kp_cd)\n",
    "desc_caps = brief(capsule, kp_caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les descripteurs obtenus, ils sont comparés un à un à l'aide d'une distance de Hamming. On affiche ensuite les meilleurs matchs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the matching between the BRIEF descriptors of the training image and the test image\n",
    "matches = []\n",
    "for i in range(len(desc_cd)):\n",
    "    for j in range(len(desc_caps)):\n",
    "        matches += [cv2.DMatch(i, j, np.sum(desc_cd[i] ^ desc_caps[j])/128)]\n",
    "\n",
    "# Order the matches in ascending order of distance\n",
    "matches = sorted(matches, key = lambda x : x.distance)\n",
    "\n",
    "# Convert keypoints to cv2 KeyPoints\n",
    "kp1 = [cv2.KeyPoint(float(x[0]), float(x[1]), 1) for x in kp_cd]\n",
    "kp2 = [cv2.KeyPoint(float(x[0]), float(x[1]), 1) for x in kp_caps]\n",
    "\n",
    "# Display the best matching points\n",
    "result = cv2.drawMatches(crew_d, kp1, capsule, kp2, matches[:30], None, flags = 2)\n",
    "plt.title(\"Matches between the original and modified capsule images\")\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
